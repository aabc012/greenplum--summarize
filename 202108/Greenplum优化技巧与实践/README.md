# Greenplum优化技巧与实践
	1、 Greenplum架构解析
		1.1 先从系统架构说起
			1.1.1 SMP - 对称多处理器架构
			1.1.2 NUMA -非一致性储存访问结构
			1.1.3 MPP-海量并行处理架构
		1.2 Greenplum 的MPP实现--简介优雅
		1.3 一切皆并行
		1.4 使用Greenplum，您能获得什么？
	2、 Greenplum重点功能
		2.1 数据分布:每个节点1/n数据
		2.2 多级分区
		2.3 多模储存/多态储存
		2.4 N个节点并行执行
		2.5 数据的额Shuffle
	3、 Greenplum优化要点
		3.1 社区提供的工具及文档
		3.2 常用压测工具及目的
		3.3 如何进行性能瓶颈分析
		3.4 问题定位的一般思路

# 1、Greenplum架构解析
## 1.1 先从系统架构说起
### 1.1.1 SMP - 对称多处理器架构
	特点
	共享储存: CPU、内存、IO
	
	不足
	扩展能力有限
	
### 1.1.2 NUMA -非一致性储存访问结构
	特点
	拥有多个CPU的模块，每个模块由多个CPU组成，有独立的本地内存；节点之间通过互联模块进行连续和信息交互，较好解决SMP系统的扩展能力。
	
	
	不足
	互联模块访问效率和本地内存访问不在一个效率层级，系统性能无法随CPU数线性增加。

### 1.1.3 MPP-海量并行处理架构
	特点
	节点互联网络:Share Nothing 结构，每个节点只访问本地内存和储存，节点信息交互和节点本身是并行处理的。
	
	对等节点: 所有数据节点角色一样，可以提升并行计算能力。
	
	不足
	1、木桶的短板效应
	2、MPP集群规模不能过大
	3、并发度不能过高
	
# 1.2 Greenplum 的MPP实现--简介优雅
	管理节点:
	Master 和 standby 节点
	
	
	传输功能:
	Interconnect 高速网络传输
	
	储存节点:
	segment 节点可以储存大量的数据
	
## 1.3 一切皆并行
	Greenplum数据库以并行的形式处理各种复杂的SQL。执行一条SQL的流程如下:
	1、一条SQL首先由Master节点进行解析分发到不同的segment节点中
	2、Segment节点汇总后的结果数据再返回到master节点
	3、postGIS 以及MADlib的支持查询
	4、支持多种外部的框架:Local Storage / HDFS/ Cloud Object Storage / GamFile / Spark / Other RDBMSes / Spring Cloud Data Flow ETL / Kafka 
	
## 1.4 使用Greenplum，您能获得什么？
	TB级数据，400个特征，之前的流程如下:
	1、数据整理
	2、数据准备
	3、信息价值和证据权重
	4、成对相对性
	5、删除高度相关变量
	6、逻辑回归
	7、计算KS分值模型验证
	8、手动预测
	
	其中2-7 之前是在SAS和Excel表格中完成的，只有1和8是在GP中完成
	
	使用Greenplum特换后的流程如下:
	1、数据整理
	2、特征生成
	3、特征选择(信息价值/方差膨胀/成对相对性)
	4、模型(逻辑回归/Elastic Net)
	5、验证
	6、预测
	

使用后的心梗提升对比:
| | 之前 | 之后 | 性能提升 | 
|:----:|:----:|:----:|:----:|
| 数据编辑/整理 | 181行代码75分钟 | 116行代码8分钟 | 9.35x |
| 特征编辑 | 439特征4517行代码100分钟 | 934特征1438行代码30分钟 | 多495个特征，快3.33x |
| 信息价值 | ~450个变量，~30分钟计算结果并写入到excel | 在GPDB中花58秒计算~200个变量的IV | 13.7x/变量 |
| 建模 | <50个变量，运行一次逻辑回归迭代需要30分钟 | 376个变量，运行一次逻辑回归迭代需要1.86分钟 | 16x/迭代 |

# 2、Greenplum重点功能
## 2.1 数据分布:每个节点1/n数据
	使用一款MPP数据库，最重要的策略和目标就是将数据均匀分布。MPP数据库会将数据进行分片，从而在并行处理的过程中，更快的得到结果。

## 2.2 多级分区
	Greenplum的分区设计与Oracle较类似。与数据分布不同的是，分区是一个逻辑的概念，而数据分布是物理的概念。在创建分区表时，在每个segment都会创建同一套完整的，包括所有表结构的分区表。在每个segment查询时，会将无用的分区裁剪，将无用的数据进行过滤，从而提升查询效率。图中可以看到，每个segment上，只有蓝色的部分参与了查询。
## 2.3 多模储存/多态储存
	行储存
	
	适合OLTP业务
	适合频繁更新或者访问大部
	分字段的场景
	
	
	列储存
	列储存更适合压缩
	查询列子集速度快
	不同列可以使用不同压缩方式:gzip，quickiz,delta,RLE,zstd
	
	外部表
	历史数据和不常访问的数据储存在HDFS或者其他外部系统中
	无缝查询所有数据
	Text，CSV，Binary，Avro，Parquet,ORC格式等
	
## 2.4 N个节点并行执行
	这一特点主要从查询计划来展开为大家进行介绍。下面的图中，将左侧的一个SELECT查询，分解成了不同的动作。在Segment 0，1，2三个机器上做并行的查询。在Greenplum中，为了提高最大的并行度，会将计算原子都提升到并行计算中。为了提高性能，我们需要不断优化执行计划，从而在在计算的过程中避免产生没有必要的代价。
	
## 2.5 数据的额Shuffle
	对Hadoop比较了解的小伙伴应该会知道，在Map和Reduce之间会有一个shuffle的操作，起到一个桥梁的作用。在Greenplum中，会涉及到数据的重分布和广播。简单来说，例如对两个表做Join操作时，在并行处理的过程中，需要同一个实例对两个表中相关数据进行相关的处理。如果数据不在此节点中，需要从别的节点取数据，这个取过来的方式就是Shuffle。
	
 
	下面的图中有个代价计算模型，是在执行计划时会做评估，如果数据量大，可能会产生数据的广播。广播的代价比较大，需要想所有节点发布同一份数据。因此我们在做数据表的设计时，应该尽量避免两个特别大的表做关联。一般在设计模型时，一般都会采用星形模型或者雪花型模型，在计算的过程中会把一些小表进行数据的重分布，从而减少代价。
	
# 3、Greenplum优化要点
## 3.1 社区提供的工具及文档
	首先是数据库初始化使用时，需要做参数预估。大家可以参考工具：
	
	https://greenplum.org/calc/
	
	数据库初始化安装前，根据硬件规划情况，使用这个计算器工具粗略计算各个vmem protect值；后期在使用过程中，如果觉得不满足，可以再上下调整。
	
	
## 3.2 常用压测工具及目的
	gpcheckperf - 定期对内存、网络、磁盘性能进行压测
	这个工具在Greenplum4、5、6版本中均有。在Greenplum启动前，需要用此工具测试整个集群的性能，如果不满足我们的经验要求，就需要大家去调整一些硬件。建议定期执行该测试，用于掌握集群硬件环境的变化情况，及时发现存在的潜在性能影响因素，并针对性的安排硬件调整计划；
	
	TPCH/TPC-DS - 选型场景下的标准测试集压测
	在选型场景下，与其他数据库选用同样的分析型测试模型，更有利于选择更有的方案，并能在同一测试场景下，不断查找并学习针对性优化方法；Greenplum的TPC-DS解决方案请参考：
	https://github.com/RunningJon/TPC-DS
	
	
	业务场景定期压测
	定期进行业务压测，方便提前察觉长期运行状态下产生的性能下降问题，并针对性的进行性能提升操作，制定日常vacuum analyze操作计划，调整数据模型。
	

## 3.3 如何进行性能瓶颈分析
	1、首先，我们需要看执行计划。如果有一条查询特别慢，我们需要查看这条查询的查询计划，来寻找慢的原因。从下往上的顺序看查询计划，主要需要关注的指标如下图。分析步骤中是否有cost值过大的场景，cost值过大说明在这一阶段，浪费了大量的时间进行处理，可以看看是否能进行优化。
	
	
	2、查看完查询计划后可以通过一些监控工具来辅助性能分析，例如官方监控工具GPCC、开源的Prometheus等。
	
## 3.4 问题定位的一般思路
	1.遇到问题不要慌，一定是有原因的，不要急于采用kill -9、重启集群或重启机器等方法来强制处理；这种处理方法通常会导致数据库宕机时间远远大于耐心分析解决的时间；
	
	2.首先看一下数据库是否还能继续使用，如果可以，尽快断开前端连接，避免新进入的查询对数据库造成更严重的影响；
	
	3.然后通过观察数据库活动查询视图(pg_stat_activity)、锁视图(pg_locks)、数据库日志(gpAdminlogs/pg_log)来查找问题的蛛丝马迹，结合前面介绍的MVCC和锁原理知识，结合数据库模式设计与日常运维逻辑之间的处理关系，来最终解决该问题。
	